{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing \n",
    "\n",
    "__NLP uses:__\n",
    "\n",
    "- Sentiment analysis\n",
    "- Predict genre of book\n",
    "- Question answering\n",
    "- Machine translator or speech recognition\n",
    "\n",
    "__Librairies:__ Spacy, NLTK ...\n",
    "\n",
    "__Bag of Words__:\n",
    "\n",
    "Very popular NLP model used to preprocess the texts to classify before fitting the classification algorithms on the observations containing the texts.\n",
    "\n",
    "It involves two things:\n",
    "\n",
    "- A vocabulary of known words\n",
    "- A measure of the presence of known words\n",
    "\n",
    "In this section, we will understand and learn how to:\n",
    "\n",
    "- Cleans text to prepare them for machine learning models\n",
    "- Create a Bag of words model\n",
    "- Apply machine learning models onto this bag of worlds model.\n",
    "\n",
    "## Practical Example\n",
    "\n",
    "The dataset contains reviews of a restaurant and the goal is to separate the good and bad reviews.\n",
    "\n",
    "The tsv format is use because the tab separator in our context use is the best to use (a comma will create other columns).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset - Quoting for ingnoring double quotes\n",
    "dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning to Bag of words\n",
    "\n",
    "The goal is to only get the relevant words and avoid punctuation, numbers, capitals or stop words and also apply stemming to get the root of a word and avoid different version of a word.\n",
    "\n",
    "At the end we will apply the tokenization process to create our bag of words by splitting the text to a matrix of words (in columns).\n",
    "\n",
    "---\n",
    "\n",
    "## __Step 1:__ Only keeping the letters and remove punctuation and numbers\n",
    "\n",
    "Using regex and sub method using a regular expression `^a-zA-Z]`\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "# adding the space to replace the removed characters\n",
    "review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before : Wow... Loved this place.\n",
      "After : Wow    Loved this place \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][0])\n",
    "print(\"Before : {}\".format(dataset['Review'][0]))\n",
    "print(\"After : {}\".format(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## __Step 2:__ Putting all the letters to lowercase\n",
    "```python\n",
    "#To lowercase\n",
    "review = review.lower()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Putting all the letters to lowercase...\n",
      "\n",
      "Before : Wow    Loved this place \n",
      "After : wow    loved this place \n"
     ]
    }
   ],
   "source": [
    "review_lower = review.lower()\n",
    "\n",
    "print(\"Putting all the letters to lowercase...\\n\")\n",
    "print(\"Before : {}\".format(re.sub('[^a-zA-Z]', ' ', dataset['Review'][0])))\n",
    "print(\"After : {}\".format(review_lower))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## __Step 3:__ Remove the non significant words (stopwords)\n",
    "\n",
    "If we are using the first line we see that words like `this` is not really usefull for machine learning algo.\n",
    "\n",
    "To remove the stopwords we are going to use yhe __nltk__ library and its stopwords list.\n",
    "\n",
    "For each review we will split the text in several words and check if each of the words are in the stopwords list.\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "\n",
    "# Importing and dowload the list of useless words\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#split the text\n",
    "review = review.split()\n",
    "\n",
    "# removing stop words - set function is used find faster stop words matches\n",
    "review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting text...\n",
      "\n",
      "Before : wow    loved this place \n",
      "After : ['Wow', 'Loved', 'this', 'place']\n"
     ]
    }
   ],
   "source": [
    "review_splitted = review.split()\n",
    "\n",
    "print(\"Splitting text...\\n\")\n",
    "\n",
    "print(\"Before : {}\".format(re.sub('[^a-zA-Z]', ' ', dataset['Review'][0]).lower()))\n",
    "print(\"After : {}\".format(review_splitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing stopwords...\n",
      "\n",
      "Before : ['Wow', 'Loved', 'this', 'place']\n",
      "After : ['Wow', 'Loved', 'place']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "review_no_stop_words = [word for word in review_splitted if not word in set(stopwords.words('english'))]\n",
    "print(\"Removing stopwords...\\n\")\n",
    "print(\"Before : {}\".format(review_splitted))\n",
    "print(\"After : {}\".format(review_no_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## __Step 4:__ Stemming\n",
    "\n",
    "To get the root of a word to avoid the different versions.\n",
    "\n",
    "```python\n",
    "# importing PorterStemmer class\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Create an object of the Porter stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Applying steamer to our list of words\n",
    "review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "\n",
    "# convert our list to text\n",
    "review = ' '.join(review)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming ...\n",
      "\n",
      "Before : ['Wow', 'Loved', 'place']\n",
      "After : ['wow', 'love', 'place']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "review_stemmed_no_stop_words = [ps.stem(word) for word in review_no_stop_words if not word in set(stopwords.words('english'))]\n",
    "print(\"Stemming ...\\n\")\n",
    "print(\"Before : {}\".format(review_no_stop_words))\n",
    "print(\"After : {}\".format(review_stemmed_no_stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreating text on each line ...\n",
      "\n",
      "Before : ['wow', 'love', 'place']\n",
      "After : wow love place\n"
     ]
    }
   ],
   "source": [
    "review_text_stemmed_no_stop_words = ' '.join(review_stemmed_no_stop_words)\n",
    "\n",
    "print(\"Recreating text on each line ...\\n\")\n",
    "print(\"Before : {}\".format(review_stemmed_no_stop_words))\n",
    "print(\"After : {}\".format(review_text_stemmed_no_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Full code for cleaning process (for each review)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/yanni-benoit-\n",
      "[nltk_data]     iyeze/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Before cleaning... ************* \n",
      " \n",
      "Wow... Loved this place. \n",
      "\n",
      "Crust is not good. \n",
      "\n",
      "Not tasty and the texture was just nasty. \n",
      "\n",
      "Stopped by during the late May bank holiday off Rick Steve recommendation and loved it. \n",
      "\n",
      "The selection on the menu was great and so were the prices. \n",
      "\n",
      "Now I am getting angry and I want my damn pho. \n",
      "\n",
      "Honeslty it didn't taste THAT fresh.) \n",
      "\n",
      "The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer. \n",
      "\n",
      "The fries were great too. \n",
      "\n",
      "A great touch.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "************* After cleaning ... ************* \n",
      "\n",
      "wow love place \n",
      "\n",
      "crust good \n",
      "\n",
      "tasti textur nasti \n",
      "\n",
      "stop late may bank holiday rick steve recommend love \n",
      "\n",
      "select menu great price \n",
      "\n",
      "get angri want damn pho \n",
      "\n",
      "honeslti tast fresh \n",
      "\n",
      "potato like rubber could tell made ahead time kept warmer \n",
      "\n",
      "fri great \n",
      "\n",
      "great touch\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the texts\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0, 1000):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    # appending clean review to our list of common words \n",
    "    corpus.append(review)\n",
    "    \n",
    "print(\"************* Before cleaning... ************* \\n \")\n",
    "print(' \\n\\n'.join(dataset['Review'][:10].tolist()))\n",
    "print(\"\\n\\n\\n\")\n",
    "print(\"************* After cleaning ... ************* \\n\")\n",
    "print(' \\n\\n'.join(corpus[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Creating the bag of words model\n",
    "\n",
    "The bag of words model is used after creating the corpus and to create it you have to take all disctinct words and create on column for each word (__tokenization__). \n",
    "That will create a matrix of the reviews and word in column, if a line contain a word there will be a 1 and 0 instead.\n",
    "\n",
    "We need to create this model to use a machine learning model because the ml model will be trained on the reviews and help it to understand the correlation (review <-> word) for the classification : __we use independent variable (word) to predict dependent variable (good or bad).__\n",
    "\n",
    "We use the [__CountVectorizer__](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) method of the __sklearn library__ to reproduce the tokenization process\n",
    "\n",
    "We already cleaned the text before so we don't need to use every parameters. \n",
    "That's should be more useful if you wand to apply more cleaning steps for complicated text like scrapped text.\n",
    "\n",
    "\n",
    "```python\n",
    "# importing the CountVectorizer method\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Creating CountVectorizer object - MaxFeatures is used to remove non relevant words (we have 1500 column).\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "\n",
    "# Fitting our corpus using tokenisation - Matrix of features or independent variable\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "#Selecting dependent variable from dataset - Reviews likes\n",
    "y = dataset.iloc[:, 1].values\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Matrix of feature... ************* \n",
      " \n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "************* Independant variable... ************* \n",
      " \n",
      "[1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, 1].values\n",
    "\n",
    "print(\"************* Matrix of feature... ************* \\n \")\n",
    "print(X[:5])\n",
    "\n",
    "print(\"************* Independant variable... ************* \\n \")\n",
    "\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Applying a Machine Learning Model\n",
    "\n",
    "The most common models used for NLP are Naive Bayes, Decision Trees and Random forest models.\n",
    "\n",
    "For our example we will try the Naive Bayes model.\n",
    "\n",
    "```python\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Prediction... ************* \n",
      " \n",
      "[1 1 1 0 0]\n",
      "************* Confusion Matrix... ************* \n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[55, 42],\n",
       "       [12, 91]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"************* Prediction... ************* \\n \")\n",
    "print(y_pred[:5])\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"************* Confusion Matrix... ************* \\n \")\n",
    "cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 55 + 91 good results so 73%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework challenge \n",
    "```\n",
    "Hello students,\n",
    "\n",
    "congratulations for having completed Part 7 - Natural Language Processing.\n",
    "\n",
    "If you are up for some practical activities, here is a little challenge:\n",
    "\n",
    "1. Run the other classification models we made in Part 3 - Classification, other than the one we used in the last tutorial.\n",
    "\n",
    "2. Evaluate the performance of each of these models. Try to beat the Accuracy obtained in the tutorial. But remember, Accuracy is not enough, so you should also look at other performance metrics like Precision (measuring exactness), Recall (measuring completeness) and the F1 Score (compromise between Precision and Recall). Please find below these metrics formulas (TP = # True Positives, TN = # True Negatives, FP = # False Positives, FN = # False Negatives):\n",
    "\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "\n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "F1 Score = 2 * Precision * Recall / (Precision + Recall)\n",
    "\n",
    "3. Try even other classification models that we haven't covered in Part 3 - Classification. Good ones for NLP include:\n",
    "\n",
    "    CART\n",
    "    C5.0\n",
    "    Maximum Entropy\n",
    "\n",
    "```\n",
    "\n",
    "## Solution\n",
    "\n",
    "To slove this homework challenge we will first:\n",
    "\n",
    "Create function to evaluate each model using performance metrics:\n",
    "   \n",
    "    - Accuracy\n",
    "    - Precision (measuring exactness)\n",
    "    - Recall (measuring completeness)\n",
    "    - F1 Score (compromise between Precision and Recall)\n",
    "\n",
    "The calculation of these metrics require arguments:\n",
    "\n",
    "    - True Positives (TP)\n",
    "    - True Negatives (TN)\n",
    "    - False Positive (FP)\n",
    "    - False Negative (FN)\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"img/cm.png\" width=\"400\" height=\"800\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find aguments and calculate metrics\n",
    "def find_TP(y_true, y_pred):\n",
    "    return sum((y_true == 1) & (y_pred == 1))\n",
    "def find_FN(y_true, y_pred):\n",
    "    return sum((y_true == 1) & (y_pred == 0))\n",
    "def find_FP(y_true, y_pred):\n",
    "    return sum((y_true == 0) & (y_pred == 1))\n",
    "def find_TN(y_true, y_pred):\n",
    "    return sum((y_true == 0) & (y_pred == 0))\n",
    "\n",
    "def find_conf_matrix_values(y_true,y_pred):\n",
    "    TP = find_TP(y_true,y_pred)\n",
    "    FN = find_FN(y_true,y_pred)\n",
    "    FP = find_FP(y_true,y_pred)\n",
    "    TN = find_TN(y_true,y_pred)\n",
    "    return TP,FN,FP,TN\n",
    "\n",
    "def my_scoring(y_true, y_pred):\n",
    "    scoring = {}\n",
    "    TP,FN,FP,TN = find_conf_matrix_values(y_true,y_pred) \n",
    "    scoring['accuracy'] = (TP + TN) / (TP + TN + FP + FN)\n",
    "    scoring['precision'] = TP / (TP + FP)\n",
    "    scoring['recall'] =  TP / (TP + FN)\n",
    "    scoring['F1_score'] = 2 * scoring['precision'] * scoring['recall']/ (scoring['precision'] + scoring['recall'])   \n",
    "    return scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Scoring ... ************* \n",
      " \n",
      "{'accuracy': 0.73, 'precision': 0.6842105263157895, 'recall': 0.883495145631068, 'F1_score': 0.7711864406779663, 'model': 'Naïve Bayes'}\n"
     ]
    }
   ],
   "source": [
    "results =[]\n",
    "## Calculating metrics\n",
    "print(\"************* Scoring ... ************* \\n \")\n",
    "\n",
    "scoring = my_scoring(y_test, y_pred)\n",
    "scoring.update({'model': 'Naïve Bayes'})\n",
    "print(scoring)\n",
    "results.append(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Dataset... ************* \n",
      " \n",
      "[0 0 0 0 0]\n",
      "************* Prediction... ************* \n",
      " \n",
      "[0 0 0 0 0]\n",
      "************* Confusion Matrix... ************* \n",
      " \n",
      "[[87 10]\n",
      " [46 57]]\n",
      "************* Scoring ... ************* \n",
      " \n",
      "{'accuracy': 0.72, 'precision': 0.8507462686567164, 'recall': 0.5533980582524272, 'F1_score': 0.6705882352941177, 'model': 'Random Forest - Entropy'}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"************* Dataset... ************* \\n \")\n",
    "print(y_test[:5])\n",
    "print(\"************* Prediction... ************* \\n \")\n",
    "print(y_pred[:5])\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"************* Confusion Matrix... ************* \\n \")\n",
    "print(cm)\n",
    "\n",
    "## Calculating metrics\n",
    "print(\"************* Scoring ... ************* \\n \")\n",
    "\n",
    "scoring = my_scoring(y_test, y_pred)\n",
    "scoring.update({'model': 'Random Forest - Entropy'})\n",
    "print(scoring)\n",
    "results.append(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Dataset... ************* \n",
      " \n",
      "[0 0 0 0 0]\n",
      "************* Prediction... ************* \n",
      " \n",
      "[0 0 1 0 1]\n",
      "************* Confusion Matrix... ************* \n",
      " \n",
      "[[82 15]\n",
      " [48 55]]\n",
      "************* Scoring ... ************* \n",
      " \n",
      "{'accuracy': 0.685, 'precision': 0.7857142857142857, 'recall': 0.5339805825242718, 'F1_score': 0.6358381502890172, 'model': 'Random Forest - Gini'}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'gini', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"************* Dataset... ************* \\n \")\n",
    "print(y_test[:5])\n",
    "print(\"************* Prediction... ************* \\n \")\n",
    "print(y_pred[:5])\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"************* Confusion Matrix... ************* \\n \")\n",
    "print(cm)\n",
    "\n",
    "## Calculating metrics\n",
    "print(\"************* Scoring ... ************* \\n \")\n",
    "\n",
    "scoring = my_scoring(y_test, y_pred)\n",
    "scoring.update({'model': 'Random Forest - Gini'})\n",
    "print(scoring)\n",
    "results.append(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree - Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Prediction... ************* \n",
      " \n",
      "[0 0 1 0 1]\n",
      "************* Confusion Matrix... ************* \n",
      " \n",
      "[[74 23]\n",
      " [35 68]]\n",
      "************* Scoring ... ************* \n",
      " \n",
      "{'accuracy': 0.71, 'precision': 0.7472527472527473, 'recall': 0.6601941747572816, 'F1_score': 0.7010309278350515, 'model': 'Decision Tree - Entropy'}\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree - Entropy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"************* Prediction... ************* \\n \")\n",
    "print(y_pred[:5])\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"************* Confusion Matrix... ************* \\n \")\n",
    "print(cm)\n",
    "\n",
    "\n",
    "## Calculating metrics\n",
    "print(\"************* Scoring ... ************* \\n \")\n",
    "scoring = my_scoring(y_test, y_pred)\n",
    "scoring.update({'model': 'Decision Tree - Entropy'})\n",
    "print(scoring)\n",
    "results.append(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree - Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Prediction... ************* \n",
      " \n",
      "[0 0 1 0 1]\n",
      "************* Confusion Matrix... ************* \n",
      " \n",
      "[[71 26]\n",
      " [44 59]]\n",
      "************* Scoring ... ************* \n",
      " \n",
      "{'accuracy': 0.65, 'precision': 0.6941176470588235, 'recall': 0.5728155339805825, 'F1_score': 0.6276595744680851, 'model': 'Decision Tree - Gini'}\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree - Entropy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'gini', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"************* Prediction... ************* \\n \")\n",
    "print(y_pred[:5])\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"************* Confusion Matrix... ************* \\n \")\n",
    "print(cm)\n",
    "\n",
    "\n",
    "## Calculating metrics\n",
    "print(\"************* Scoring ... ************* \\n \")\n",
    "scoring = my_scoring(y_test, y_pred)\n",
    "scoring.update({'model': 'Decision Tree - Gini'})\n",
    "print(scoring)\n",
    "results.append(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Prediction... ************* \n",
      " \n",
      "[0 0 0 0 0]\n",
      "************* Confusion Matrix... ************* \n",
      " \n",
      "[[ 97   0]\n",
      " [103   0]]\n",
      "************* Scoring ... ************* \n",
      " \n",
      "{'accuracy': 0.485, 'precision': nan, 'recall': 0.0, 'F1_score': nan, 'model': 'Kernel SVM'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "# Kernel SVM - Kernel RBF\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"************* Prediction... ************* \\n \")\n",
    "print(y_pred[:5])\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"************* Confusion Matrix... ************* \\n \")\n",
    "print(cm)\n",
    "\n",
    "## Calculating metrics\n",
    "print(\"************* Scoring ... ************* \\n \")\n",
    "\n",
    "scoring = my_scoring(y_test, y_pred)\n",
    "scoring.update({'model': 'Kernel SVM'})\n",
    "print(scoring)\n",
    "results.append(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Prediction... ************* \n",
      " \n",
      "[0 0 0 0 0]\n",
      "************* Confusion Matrix... ************* \n",
      " \n",
      "[[74 23]\n",
      " [33 70]]\n",
      "************* Scoring ... ************* \n",
      " \n",
      "{'accuracy': 0.72, 'precision': 0.7526881720430108, 'recall': 0.6796116504854369, 'F1_score': 0.7142857142857143, 'model': 'SVM'}\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"************* Prediction... ************* \\n \")\n",
    "print(y_pred[:5])\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"************* Confusion Matrix... ************* \\n \")\n",
    "print(cm)\n",
    "\n",
    "## Calculating metrics\n",
    "print(\"************* Scoring ... ************* \\n \")\n",
    "\n",
    "scoring = my_scoring(y_test, y_pred)\n",
    "scoring.update({'model': 'SVM'})\n",
    "print(scoring)\n",
    "results.append(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K - NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Prediction... ************* \n",
      " \n",
      "[0 1 1 0 1]\n",
      "************* Confusion Matrix... ************* \n",
      " \n",
      "[[74 23]\n",
      " [55 48]]\n",
      "************* Scoring ... ************* \n",
      " \n",
      "{'accuracy': 0.61, 'precision': 0.676056338028169, 'recall': 0.46601941747572817, 'F1_score': 0.5517241379310345, 'model': 'K-NN'}\n"
     ]
    }
   ],
   "source": [
    "# K-NN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"************* Prediction... ************* \\n \")\n",
    "print(y_pred[:5])\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"************* Confusion Matrix... ************* \\n \")\n",
    "print(cm)\n",
    "\n",
    "## Calculating metrics\n",
    "print(\"************* Scoring ... ************* \\n \")\n",
    "\n",
    "scoring = my_scoring(y_test, y_pred)\n",
    "scoring.update({'model': 'K-NN'})\n",
    "print(scoring)\n",
    "results.append(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Prediction... ************* \n",
      " \n",
      "[0 0 0 0 0]\n",
      "************* Confusion Matrix... ************* \n",
      " \n",
      "[[76 21]\n",
      " [37 66]]\n",
      "************* Scoring ... ************* \n",
      " \n",
      "{'accuracy': 0.71, 'precision': 0.7586206896551724, 'recall': 0.6407766990291263, 'F1_score': 0.6947368421052632, 'model': 'Logistic Regression'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"************* Prediction... ************* \\n \")\n",
    "print(y_pred[:5])\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"************* Confusion Matrix... ************* \\n \")\n",
    "print(cm)\n",
    "\n",
    "## Calculating metrics\n",
    "print(\"************* Scoring ... ************* \\n \")\n",
    "\n",
    "scoring = my_scoring(y_test, y_pred)\n",
    "scoring.update({'model': 'Logistic Regression'})\n",
    "print(scoring)\n",
    "results.append(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - C5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Prediction... ************* \n",
      " \n",
      "[0 0 0 0 0]\n",
      "************* Confusion Matrix... ************* \n",
      " \n",
      "[[74 23]\n",
      " [33 70]]\n",
      "************* Scoring ... ************* \n",
      " \n",
      "{'accuracy': 0.72, 'precision': 0.7526881720430108, 'recall': 0.6796116504854369, 'F1_score': 0.7142857142857143, 'model': 'Logistic Regression - C5.0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - C5.0\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, C=5.0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"************* Prediction... ************* \\n \")\n",
    "print(y_pred[:5])\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"************* Confusion Matrix... ************* \\n \")\n",
    "print(cm)\n",
    "\n",
    "## Calculating metrics\n",
    "print(\"************* Scoring ... ************* \\n \")\n",
    "\n",
    "scoring = my_scoring(y_test, y_pred)\n",
    "scoring.update({'model': 'Logistic Regression - C5.0'})\n",
    "print(scoring)\n",
    "results.append(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Maximum entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Prediction... ************* \n",
      " \n",
      "[0 0 0 0 0]\n",
      "************* Confusion Matrix... ************* \n",
      " \n",
      "[[76 21]\n",
      " [37 66]]\n",
      "************* Scoring ... ************* \n",
      " \n",
      "{'accuracy': 0.71, 'precision': 0.7586206896551724, 'recall': 0.6407766990291263, 'F1_score': 0.6947368421052632, 'model': 'Logistic Regression - Maximum entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - Maximum entropy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, C=1.0, penalty='l2')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"************* Prediction... ************* \\n \")\n",
    "print(y_pred[:5])\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"************* Confusion Matrix... ************* \\n \")\n",
    "print(cm)\n",
    "\n",
    "## Calculating metrics\n",
    "print(\"************* Scoring ... ************* \\n \")\n",
    "\n",
    "scoring = my_scoring(y_test, y_pred)\n",
    "scoring.update({'model': 'Logistic Regression - Maximum entropy'})\n",
    "print(scoring)\n",
    "results.append(scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.771186</td>\n",
       "      <td>0.730</td>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.883495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.720</td>\n",
       "      <td>Random Forest - Entropy</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.553398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.635838</td>\n",
       "      <td>0.685</td>\n",
       "      <td>Random Forest - Gini</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.533981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.710</td>\n",
       "      <td>Decision Tree - Entropy</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.660194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.627660</td>\n",
       "      <td>0.650</td>\n",
       "      <td>Decision Tree - Gini</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.572816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485</td>\n",
       "      <td>Kernel SVM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.720</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.679612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.610</td>\n",
       "      <td>K-NN</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.466019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.694737</td>\n",
       "      <td>0.710</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.640777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.720</td>\n",
       "      <td>Logistic Regression - C5.0</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.679612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.694737</td>\n",
       "      <td>0.710</td>\n",
       "      <td>Logistic Regression - Maximum entropy</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.640777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F1_score  accuracy                                  model  precision  \\\n",
       "0   0.771186     0.730                            Naïve Bayes   0.684211   \n",
       "1   0.670588     0.720                Random Forest - Entropy   0.850746   \n",
       "2   0.635838     0.685                   Random Forest - Gini   0.785714   \n",
       "3   0.701031     0.710                Decision Tree - Entropy   0.747253   \n",
       "4   0.627660     0.650                   Decision Tree - Gini   0.694118   \n",
       "5        NaN     0.485                             Kernel SVM        NaN   \n",
       "6   0.714286     0.720                                    SVM   0.752688   \n",
       "7   0.551724     0.610                                   K-NN   0.676056   \n",
       "8   0.694737     0.710                    Logistic Regression   0.758621   \n",
       "9   0.714286     0.720             Logistic Regression - C5.0   0.752688   \n",
       "10  0.694737     0.710  Logistic Regression - Maximum entropy   0.758621   \n",
       "\n",
       "      recall  \n",
       "0   0.883495  \n",
       "1   0.553398  \n",
       "2   0.533981  \n",
       "3   0.660194  \n",
       "4   0.572816  \n",
       "5   0.000000  \n",
       "6   0.679612  \n",
       "7   0.466019  \n",
       "8   0.640777  \n",
       "9   0.679612  \n",
       "10  0.640777  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(results)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
